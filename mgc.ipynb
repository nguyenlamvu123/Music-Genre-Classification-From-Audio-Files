{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcbc9c3-80de-4494-9f93-ac2b0116c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, librosa, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"/home/bhm-ai/music_classification\"\n",
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "songname = f'{path}/Data/genres_original/jazz/jazz.00029.wav'\n",
    "\n",
    "num_mfcc = 20\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "\n",
    "# header = 'filename chroma_stft spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "# header = 'filename chroma_stft_mean chroma_stft_var spectral_centroid_mean spectral_centroid_var spectral_bandwidth_mean spectral_bandwidth_var rolloff_mean rolloff_var zero_crossing_rate_mean zero_crossing_rate_var'\n",
    "header = 'filename chroma_stft_mean chroma_stft_var rms_mean rms_var spectral_centroid_mean spectral_centroid_var spectral_bandwidth_mean spectral_bandwidth_var rolloff_mean rolloff_var zero_crossing_rate_mean zero_crossing_rate_var harmony_mean harmony_var perceptr_mean perceptr_var tempo'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}_mean mfcc{i}_var'\n",
    "header += ' label'\n",
    "header = header.split()\n",
    "\n",
    "demo = False \n",
    "pre_dataset = False \n",
    "# epochs = 900 if not demo else 5\n",
    "epochs = 600 if not demo else 5\n",
    "\n",
    "converter = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12a827-2868-4dec-ad60-ed0f58bd169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model using the following parameters\n",
    "# metrics = accuracy\n",
    "# epochs = 600\n",
    "# loss = sparse_categorical_crossentropy\n",
    "# batch_size = 256\n",
    "# optimizer = adam\n",
    "\n",
    "def train_model(model,epochs,optimizer):\n",
    "    batch_size=256\n",
    "    model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=epochs,batch_size=batch_size)\n",
    "\n",
    "def Validation_plot(history):\n",
    "    print(\"Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n",
    "    pd.DataFrame(history.history).plot(figsize=(12,6))\n",
    "    plt.show()\n",
    "\n",
    "def readdata(df):\n",
    "    df = df.drop(labels=\"filename\",axis=1)    \n",
    "    \n",
    "    fit = StandardScaler()\n",
    "    X = fit.fit_transform(np.array(df.iloc[:,:-1],dtype=float))\n",
    "    return X, df\n",
    "\n",
    "# def extractfeature(y, sr, filename='_', g='_'):  # 60 columns; missing rms, harmony, perceptr, tempo\n",
    "\n",
    "#     chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "#     spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "#     spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "#     rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "#     zcr = librosa.feature.zero_crossing_rate(y)\n",
    "#     mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "#     to_append = f'{filename} {np.mean(chroma_stft)} {np.var(chroma_stft)} {np.mean(spec_cent)} {np.var(spec_cent)} {np.mean(spec_bw)} {np.var(spec_bw)} {np.mean(rolloff)} {np.var(rolloff)} {np.mean(zcr)} {np.var(zcr)}'\n",
    "#     for e in mfcc:\n",
    "#         to_append += f' {np.mean(e)} {np.var(e)}'\n",
    "#     to_append += f' {g}'\n",
    "#     return to_append\n",
    "\n",
    "\n",
    "def extractfeature(y, sr, filename='_', g='_'):\n",
    "    chroma_hop_length = 512 #5000?\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=chroma_hop_length)\n",
    "    RMSEn= librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    harmony, perceptr = librosa.effects.hpss(y=y)\n",
    "    mfcc = librosa.feature.mfcc(y=y,sr=sr, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    tempo, _ = librosa.beat.beat_track(y=y, sr = sr)\n",
    "    to_append = f'{filename} {chroma_stft.mean()} {chroma_stft.var()} {RMSEn.mean()} {RMSEn.var()} {spec_cent.mean()} {spec_cent.var()} {spec_bw.mean()} {spec_bw.var()} {rolloff.mean()} {rolloff.var()} {zcr.mean()} {zcr.var()} {harmony.mean()} {harmony.var()} {perceptr.mean()} {perceptr.var()} {tempo[0]}'\n",
    "    # for e in mfcc:\n",
    "    #     to_append += f' {np.mean(e)} {np.var(e)}'\n",
    "    mfcc = mfcc.T\n",
    "    for x in range(20):\n",
    "        to_append += f' {mfcc[:,x].mean()} {mfcc[:,x].var()}'\n",
    "    to_append += f' {g}'\n",
    "    return to_append\n",
    "\n",
    "\n",
    "def extractfeature_(y, sr, filename='_', g='_'):  # 27 columns \n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    to_append += f' {g}'\n",
    "    return to_append\n",
    "\n",
    "\n",
    "def big_cnn_model(train=True):\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model\n",
    "    if not train:\n",
    "        model = tf.keras.models.load_model(\"model.keras\")\n",
    "    else:\n",
    "        # We used different layers to train the neural network by importing keras library from tensorflow framework \n",
    "        # for input and hidden neurons we use the most widly used activation function which is relu where as for output neurons we uses softmax activation function\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(X.shape[1],)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            \n",
    "            tf.keras.layers.Dense(512,activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            \n",
    "            tf.keras.layers.Dense(256,activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            \n",
    "            tf.keras.layers.Dense(128,activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            \n",
    "            tf.keras.layers.Dense(64,activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            \n",
    "            tf.keras.layers.Dense(32,activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            \n",
    "            tf.keras.layers.Dense(10,activation='softmax'),\n",
    "        ])\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.000146)\n",
    "        model.compile(optimizer=optimizer,\n",
    "                     loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "        model.summary()\n",
    "        model_history=train_model(model=model, epochs=epochs, optimizer='adam')\n",
    "        \n",
    "        test_loss,test_acc=model.evaluate(X_test,y_test,batch_size=256)\n",
    "        print(\"The test loss is \",test_loss)\n",
    "        print(\"The best accuracy is: \",test_acc*100)\n",
    "        \n",
    "        Validation_plot(model_history)\n",
    "        model.save(\"model.keras\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def cnn_model(train=True):\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model\n",
    "    if not train:\n",
    "        model = tf.keras.models.load_model(\"model.keras\")\n",
    "    else:\n",
    "        # We used different layers to train the neural network by importing keras library from tensorflow framework \n",
    "        # for input and hidden neurons we use the most widly used activation function which is relu where as for output neurons we uses softmax activation function\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "        model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.000146)\n",
    "        model.compile(optimizer=optimizer,\n",
    "                     loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "        model.summary()\n",
    "        model_history=train_model(model=model, epochs=epochs, optimizer='adam')\n",
    "        \n",
    "        test_loss,test_acc=model.evaluate(X_test,y_test,batch_size=256)\n",
    "        print(\"The test loss is \",test_loss)\n",
    "        print(\"The best accuracy is: \",test_acc*100)\n",
    "        \n",
    "        Validation_plot(model_history)\n",
    "        model.save(\"model.keras\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d159f71-99e7-4831-8faf-694c54878107",
   "metadata": {},
   "source": [
    "## tiền xử lí dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d0926-3160-4a33-8bd5-901368f109f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predat_():\n",
    "    return pd.read_csv(path + \"/Data/features_3_sec.csv\")\n",
    "\n",
    "def predat():\n",
    "    if pre_dataset:\n",
    "        file = open(f'{path}/try_running__features_3_sec.csv', 'w', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)\n",
    "        genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()\n",
    "        for g in genres:\n",
    "            print(g)\n",
    "            ldir = list(os.listdir(f'{path}/Data/genres_original/{g}'))\n",
    "            listfn = ldir[:5] if demo else ldir\n",
    "            for filename in listfn:\n",
    "                songname = f'{path}/Data/genres_original/{g}/{filename}'\n",
    "                y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "                to_append = extractfeature(y, sr, filename, g)\n",
    "                file = open(f'{path}/try_running__features_3_sec.csv', 'a', newline='')\n",
    "                with file:\n",
    "                    writer = csv.writer(file)\n",
    "                    writer.writerow(to_append.split())\n",
    "    return pd.read_csv(f\"{path}/try_running__features_3_sec.csv\")\n",
    "\n",
    "df = predat_()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef9694-bad0-48bb-86fc-cd8224e1b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['filename'] == 'jazz.00029.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9374b-96e3-48e1-ba79-6d7f30b527a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns containing missing values\",list(df.columns[df.isnull().any()]))\n",
    "\n",
    " # Label Encoding - encod the categorical classes with numerical integer values for training\n",
    "\n",
    "# Blues - 0\n",
    "# Classical - 1\n",
    "# Country - 2\n",
    "# Disco - 3\n",
    "# Hip-hop - 4 \n",
    "# Jazz - 5  \n",
    "# Metal - 6 \n",
    "# Pop - 7\n",
    "# Reggae - 8\n",
    "# Rock - 9\n",
    "class_encod = df.iloc[:,-1]\n",
    "Y = converter.fit_transform(class_encod)\n",
    "\n",
    "X, df = readdata(df)\n",
    "# df = df.drop(labels=\"length\",axis=1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3fb91a-d0bc-43ad-a8da-0f4b9ee49bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df.isnull())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a5d05-3e3e-4a9b-8e16-ca6ef78a5591",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8709ae2-5948-4f6e-944e-3f2076c3019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = cnn_model(False)  # cnn_model(True)  # \n",
    "model = big_cnn_model(True)  # big_cnn_model(False)  # big_cnn_model(True)  # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d58ced-6960-44c7-9479-a22e8c943d76",
   "metadata": {},
   "source": [
    "trích xuất đặc trưng, lưu vào csv  # reference more at https://github.com/danyalimran93/Music-Emotion-Recognition/blob/master/Feature-Extraction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97579844-1e56-43b3-9b54-4aaeec602ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('try_running__Extracted___Data.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "\n",
    "y, sr = librosa.load(songname, mono=True, duration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2166ec-af24-4116-a65a-860f01e0db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_append = extractfeature(y, sr, filename='_', g='_')\n",
    "len(to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf712b5f-b417-4bfc-9de9-033be68c8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('try_running__Extracted___Data.csv', 'a', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(to_append.split())\n",
    "\n",
    "df = pd.read_csv('try_running__Extracted___Data.csv')\n",
    "# # assert len(list(df.columns[df.isnull().any()])) > 0\n",
    "X, df = readdata(df)\n",
    "# df = df.drop(labels=\"label\",axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d36fa00-e626-4820-a918-8ed9d3d36a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = model.predict(X)\n",
    "pred_ind = np.argmax(pred_x, axis=1)\n",
    "# print(labels[pred_ind])\n",
    "print(converter.inverse_transform(pred_ind)[:1])\n",
    "# print(pred_ind)\n",
    "# print(class_encod)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
